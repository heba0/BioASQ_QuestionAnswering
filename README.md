# BioAsq_QuestionAnswering


In this project we tackle the BioASQ challenge, task 12b. 

Dataset can be downloaded from the [BioASQ  website](http://participants-area.bioasq.org/datasets/), under Datasest for task B tab.

For training, we used the dataset for year 2024.

Performance: 

List-BioBERT

Final Evaluation Results: 
Average F1 score:  0.4337921142578125
Average Recall score:  0.41207313537597656
Average Precision score:  0.46752673387527466
Average ROUGE 1 score:  0.04

List-BlueBERT

Final Evaluation Results: 
Average F1 score:  0.39047694206237793
Average Recall score:  0.3740953207015991
Average Precision score:  0.4181733727455139
Average ROUGE 1 score:  0.01

List-RoBERTa

Final Evaluation Results: 
Average F1 score:  0.46330931782722473
Average Recall score:  0.44991764426231384
Average Precision score:  0.4867532253265381
Average ROUGE 1 score:  0.015714285714285715